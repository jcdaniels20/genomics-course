---
title: "Lab 7: RNA-Seq workflow: gene-level exploratory analysis and differential expression"
author: "Jarrod Daniels"
date: "10/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction (1-1.1)

The first part of the workflow (1-1.1) introduces us to Bioconductor as well as some of its main packages and how they are used for analysis of RNA-seq data.

It also introduces to the data that will be used throuhgout the workflow, specifically RNA-seq data on airway smooth muscle cells that were treated with dexamethasone

# 2: Perparing quantification input to DESeq2

The workflow also goes into detail about preping quanitfication data in the form of a matrix/un-normalized counts. It is also important to note that the values in these matrices should be counts or estimatted counts of sequencing reads/fragments

## 2.1 - Transcript quantification and tximport / tximeta

One of the purposes of this workflow is to demonstrate how to import transcript-level quantification data, aggregating to the gene-level with tximport or tximeta

The workflow also goes over how transcription methods/technologies such as Salmon can erform mapping or alignment of reads to reference transcripts, outputting estimated counts per transcript as well as effective transcript lengths which summarize bias effects. Once this is done, then we can use tximport or tximeta to assemble estimated count and offset matrices for use with Bioconductor differential gene expression packages, as will be demonstrated below.

There are advantages to using transcript abundance quantifiers in conjunction with tximport/tximeta to produce gene-level count matrices and normalizing offsets…. they are

1: this approach corrects for any potential changes in gene length across samples

2: some of these methods are substantially faster and require less memory and disk usage compared to alignment-based methods

3: it is possible to avoid discarding those fragments that can align to multiple genes with homologous sequence

## 2.2 - Quantifying with Salmon

This section gives a brief tutorial on how to use Salmon. The data provided to us appears to be already quantified so this is good for later uses.

## 2.3 - Reading in data with tximeta

to begin we must first begin bt loading the package with the data example

```{r}
library("airway")
```

The R function system.file can be used to find out where on your computer the files from a package have been installed. Here we ask for the full path to the extdata directory, where R packages store external data, that is part of the airway package.

```{r}
dir <- system.file("extdata", package="airway", mustWork=TRUE)
```

We will now list the files in the directory and specifically list the files/directories that are within the quants directory

```{r}
list.files(dir)
list.files(file.path(dir, "quants"))
```

Now we move on to loading the sample table CSV file with the read csv function

```{r}
csvfile <- file.path(dir, "sample_table.csv")
coldata <- read.csv(csvfile, row.names=1, stringsAsFactors=FALSE)
coldata
```

Now, to demonstrate loading the salmon quantifiation data into R, we will just work with the two samples that are provided in the airway package. We will also create a column called “names” and another called “files”

```{r}

coldata <- coldata[1:2,]
coldata$names <- coldata$Run
coldata$files <- file.path(dir, "quants", coldata$names, "quant.sf.gz")
file.exists(coldata$files)

```

Next, we load the tximeta package and run it on our coldata (make sure to select two if prompted)

```{r}
library("tximeta")
se <- tximeta(coldata)
```

Once this is complete, we can now look at some of the dimensions of the se object we created

```{r}
dim(se)
head(rownames(se))
```

Because this workflow/tutorial is concerned with gene-level analysis, we will now summarize the tracsript-level quantifications to the gene level. The correct transcript-to-gene mapping table is automatically created based on the metadata stored within the se object.

```{r}
gse <- summarizeToGene(se)
```

With this done we can once again look at the dimensions to see that they are reduced and the row IDs are now gene IDs

```{r}
dim(gse)
head(rownames(gse))
```

## 2.4 - DESeq2 import functions

While there is no code for this section, it is important to note that there are other tools/inputs for DESeq2 that all have specialized uses.

## 2.5 - SummarizedExperiment

We will now view the component parts of a SummmarizedExperiment object

```{r}
par(mar=c(0,0,0,0))
plot(1,1,xlim=c(0,100),ylim=c(0,100),bty="n",
     type="n",xlab="",ylab="",xaxt="n",yaxt="n")
polygon(c(45,90,90,45),c(5,5,70,70),col="pink",border=NA)
polygon(c(45,90,90,45),c(68,68,70,70),col="pink3",border=NA)
text(67.5,40,"assay(s)")
text(67.5,35,'e.g. "counts", ...')
polygon(c(10,40,40,10),c(5,5,70,70),col="skyblue",border=NA)
polygon(c(10,40,40,10),c(68,68,70,70),col="skyblue3",border=NA)
text(25,40,"rowRanges")
polygon(c(45,90,90,45),c(75,75,95,95),col="palegreen",border=NA)
polygon(c(45,47,47,45),c(75,75,95,95),col="palegreen3",border=NA)
text(67.5,85,"colData")
```

We now will load the full count matrix corresponding to all samples and all data, which is provided in the airway package, and will continue the analysis with the full data object.

```{r}
data(gse)
gse
```

The counts shown above are the first matrix, we can exam them using the assayNames function

```{r}
assayNames(gse)
```

```{r}
head(assay(gse), 3)
colSums(assay(gse))
```

We will now use rowRanges, which shows the ranges for the first and last five genes

```{r}
rowRanges(gse)
```

the rowRanges also contains metadata within it that we can view using the seqinfo function

```{r}
seqinfo(rowRanges(gse))
```

The colData for the SummarizedExperiment reflects the data frame that was provided to the tximeta function for importing the qualification data we can now see these column names

```{r}
colData(gse)
```

## 2.6 - Branching Point

At this point, we have counted the fragments which overlap the genes in the gene model we specified. From this point forward we could use a variety of Biodonductor pakcages for data exploration. For the rest of this tutorial however we will continue using DEseq

# 3: The DESeqDataSet object, sample information and the design formula

Bioconductor software packages often define and use a custom class for storing data that makes sure that all the needed data slots are consistently provided and fulfill the requirements. The Bioconductor software also has general data classes that can be used to move data between packages (such as SummarizedExperiment).

for this case (with DESeq2) the custom class is called DESeqDataSet which is built on top of the Summarized experiment class (this means it is easy to convert summarizedExpirment objects to DESeqDataSet objects)

Two big differences between the two data classes is that…

1: the assay slot is instead accessed using the counts accessor function, and the DESeqDataSet class enforces that the values in this matrix are non-negative integers.

2: the DESeqDataSet has an associated design formula. The design formula tells which columns in the sample information table (colData) specify the experimental design and how these factors should be used in the analysis.

To begin, we can look at the columns of the colData of gse. We can look at each column specifically by utalizing the $.

```{r}
gse$donor
gse$condition
```

It is also possible to change the names of the levels on a variable. It is critical however not to change the order…

```{r}
gse$cell <- gse$donor
gse$dex <- gse$condition
```

Below we will rename “Untreated” to “untrt” and “Dexamethasone” to “trt”

```{r}
levels(gse$dex)
levels(gse$dex) <- c("untrt", "trt")
```

Note: it is prefered in R that the first level of a factor be the reference level (e.g. control, or untreated samples). In this case, when the colData table was assembled the untreated samples were already set as the reference, but if this were not the case we could use relevel as shown below. While levels(…) <- above was simply for renaming the character strings associated with levels, relevel is a very different function, which decides how the variables will be coded, and how contrasts will be computed. For a two-group comparison, the use of relevel to change the reference level would flip the sign of a coefficient associated with a contrast between the two groups.

```{r}
library("magrittr")
gse$dex %<>% relevel("untrt")
gse$dex
```

%<>% is the compound assignment pipe-operator from the magrittr package, the above line of code is a concise way of saying:

(we do not actually want to run this code so eval will be set to false)

```{r}
gse$dex <- relevel(gse$dex, "untrt")
```

For running DESeq2 models, you can use R’s formula notation to express any fixed-effects experimental design. Note that DESeq2 uses the same formula notation as, for instance, the lm function of base R.If the research aim is to determine for which genes the effect of treatment is different across groups, then interaction terms can be included and tested using a design such as [~ group + treatment + group:treatment].

In the following sections, we will demonstrate the construction of the DESeqDataSet from two starting points:

-> from a SummarizedExperiment object -> from a count matrix and a sample information table

## 3.1 - Starting from Summarized Experiment

we can quickly check the millions of frgaments that could be mapped by the salmon data to the genes using the round function (second argument indicates decimal places)

```{r}
round( colSums(assay(gse)) / 1e6, 1 )
```

We can now construct a DESewDataSet from our gse object. to do this we will need the library DESeq2

```{r}
library("DESeq2")
dds <- DESeqDataSet(gse, design = ~ cell + dex)
```

## 3.2 - Starting from count matrices

The information in a SummarizedExperiment object can be accessed with accessor functions. For example, to see the actual data, i.e., here, the fragment counts, we use the assay function. (The head function restricts the output to the first few lines.)

```{r}
countdata <- round(assays(gse)[["counts"]])
head(countdata, 3)
```

In the count matrix above, each row represents a gene, each column represents a sequenced RNA library, and the values give the estimated counts of fragments that were probabilistically assigned to the respective gene in each library by Salmon

Note: If you’ve imported the count data in some other way, for example loading a pre-computed count matrix, it is very important to check manually that the columns of the count matrix correspond to the rows of the sample information table.

```{r}
coldata <- colData(gse)
```

We now have all the ingredients to prepare our data object in a form that is suitable for analysis.

Now we will construct the DESeqDataSet object

```{r}
ddsMat <- DESeqDataSetFromMatrix(countData = countdata,
                                 colData = coldata,
                                 design = ~ cell + dex)
```

# 4: Exploratory analysis and visualization

The first path of this workflow involves transforming the counts in order to visually explore sample relationships

## 4.1 Pre-Filtering the dataset

To filter the data, we have to remove the rows that have no or nearly no infromation about the amount of gene expression. this can be done by removing rows that have no counts or only a single count across all samples.

```{r}
nrow(dds)
```

```{r}
keep <- rowSums(counts(dds)) > 1
dds <- dds[keep,]
nrow(dds)
```

Data can be filtered even further. in the example below we look for rows with at least 3 samples that have a count of 10 or higher.

```{r}
keep <- rowSums(counts(dds) >= 10) >= 3
```

## 4.2 - The variance stabalizing transformation and the rlog

Many common statistical methods for exploratory analysis of multidimensional data, for example clustering and principal components analysis (PCA), work best for data that generally has the same range of variance at different ranges of the mean values.When the expected amount of variance is approximately the same across different mean values, the data is said to be homoskedastic.For RNA-seq counts, however, the expected variance grows with the mean.For example, if one performs PCA directly on a matrix of counts or normalized counts, the resulting plot typically depends mostly on the genes with highest counts because they show the largest absolute differences between samples. A simple and often used strategy to avoid this is to take the logarithm of the normalized count values plus a pseudocount of 1.

This choice of pseudocount is important however. Depending on the pseudo count, the genes with the very lowest counts will contriube to much of the plots noise. This is because taking the logarithm of small counts actually inflates their variance.

This is concept is seen below in the following graphs

```{r}
lambda <- 10^seq(from = -1, to = 2, length = 1000)
cts <- matrix(rpois(1000*100, lambda), ncol = 100)
library("vsn")
meanSdPlot(cts, ranks = FALSE)
```

The next graph if for the logarithm-transformed counts…

```{r}
log.cts.one <- log2(cts + 1)
meanSdPlot(log.cts.one, ranks = FALSE)
```

The logarithm with a small pseudocount amplifies differences when the values are close to 0. The low count genes with low signal-to-noise ratio will overly contribute to sample-sample distances and PCA plots.

To combat this, DESeq2 offers two transformative solutions to stabalize the variance across the mean

1: variance stabalizing transfromation (VST) 2: the regularized-logarithm transformation (rlog)

The VST is much faster to compute and is less sensitive to high count outliers than the rlog

The rlog tends to work well on small datasets (n < 30), potentially outperforming the VST when there is a wide range of sequencing depth across samples (an order of magnitude difference).

VST is reccomended for medium to large datasets

Below we will use both…..

VST:

```{r}
vsd <- vst(dds, blind = FALSE)
head(assay(vsd), 3)
colData(vsd)
```

rlog:

```{r}
rld <- rlog(dds, blind = FALSE)
head(assay(rld), 3)
```

blind = false means that differences between cell lines and treatment (the variables in the design) will not contribute to the expected variance-mean trend of the experiment.For a fully unsupervised transformation, one can set blind = TRUE (which is the default).

in the figure below we plot the first sample against the second, first simply using the log2 function (after adding 1, to avoid taking the log of zero), and then using the VST and rlog-transformed values. For the log2 approach, we need to first estimate size factors to account for sequencing depth, and then specify normalized=TRUE. Sequencing depth correction is done automatically for the vst and rlog.

```{r}
library("dplyr")
library("ggplot2")


dds <- estimateSizeFactors(dds)
```


```{r}
df <- bind_rows(
  as_data_frame(log2(counts(dds, normalized=TRUE)[, 1:2]+1)) %>%
    mutate(transformation = "log2(x + 1)"),
  as_data_frame(assay(vsd)[, 1:2]) %>% mutate(transformation = "vst"),
  as_data_frame(assay(rld)[, 1:2]) %>% mutate(transformation = "rlog"))
```

```{r}
colnames(df)[1:2] <- c("x", "y")  

ggplot(df, aes(x = x, y = y)) + geom_hex(bins = 80) +
  coord_fixed() + facet_grid( . ~ transformation) 
```

Looking at the figure above, We can see how genes with low counts (bottom left-hand corner) seem to be excessively variable on the ordinary logarithmic scale, while the VST and rlog compress differences for the low count genes for which the data provide little information about differential expression.

## 4.3 - Sample distances 

We use the R function dist to calculate the Euclidean distance between samples. To ensure we have a roughly equal contribution from all genes, we use it on the VST data. We need to transpose the matrix of values using t, because the dist function expects the different samples to be rows of its argument, and different dimensions (here, genes) to be columns.

```{r}
sampleDists <- dist(t(assay(vsd)))
sampleDists
```

We can visualize distances using a heat map… first we must download the right packages
```{r}
library("pheatmap")
library("RColorBrewer")
```

We must manually provide sampleDists to the clustering-distances argument to get the mat arranged by distances.

We can specify collor using the RcolorBrewer package
```{r}
sampleDistMatrix <- as.matrix( sampleDists )
rownames(sampleDistMatrix) <- paste( vsd$dex, vsd$cell, sep = " - " )
colnames(sampleDistMatrix) <- NULL
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
pheatmap(sampleDistMatrix,
         clustering_distance_rows = sampleDists,
         clustering_distance_cols = sampleDists,
         col = colors)
```

You can also calculate sample distances using the Poisson Distance implemented by the PoiClaclu package. This is displayed in the figure below.

```{r}
library("PoiClaClu")
poisd <- PoissonDistance(t(counts(dds)))

## ----poisdistheatmap, fig.width = 6.1, fig.height = 4.5--------------------
samplePoisDistMatrix <- as.matrix( poisd$dd )
rownames(samplePoisDistMatrix) <- paste( dds$dex, dds$cell, sep=" - " )
colnames(samplePoisDistMatrix) <- NULL
pheatmap(samplePoisDistMatrix,
         clustering_distance_rows = poisd$dd,
         clustering_distance_cols = poisd$dd,
         col = colors)
```

## 4.4 - PCA plot

Another way to visualize sample-to-sample distances is a principal components analysis

In this graph, the data points are projected onto the 2D plane sich that they spread out into two directions that explain most of the differences.

X-axis is the PC1 variance (seperates the data the most)

Y-axis is PC2 variance

The total perent variance in each direction is printed on the axis (they do not need to add up to 100)

```{r}
plotPCA(vsd, intgroup = c("dex", "cell"))
```

above figure, each unique combination of treatment and cell line is given its own color.

It is possible to create a PCA plot from scratch using ggplot2

```{r}
pcaData <- plotPCA(vsd, intgroup = c( "dex", "cell"), returnData = TRUE)
pcaData

percentVar <- round(100 * attr(pcaData, "percentVar"))
```

This data can now be used to build a second plot. Point color: dexamethasone treatment Point shape: cell line

```{r}
ggplot(pcaData, aes(x = PC1, y = PC2, color = dex, shape = cell)) +
  geom_point(size =3) +
  xlab(paste0("PC1: ", percentVar[1], "% variance")) +
  ylab(paste0("PC2: ", percentVar[2], "% variance")) +
  coord_fixed() +
  ggtitle("PCA with VST data")
```

The plot above shows the difference between cells are considerable, though not stronger than the differences due to treatment with dexamethasone

## 4.5 - PCA plot using Generalized PCA

Another technique for performing dimension reduction on data that is not Normally distributed (e.g. over-dispersed count data) is generalized principal component analysis, or GLM-PCA as implemented in the package glmpca

We willnow see the apllication of this in the figure below

```{r}
library("glmpca")
```

```{r}
gpca <- glmpca(counts(dds), L=2)
gpca.dat <- gpca$factors
gpca.dat$dex <- dds$dex
gpca.dat$cell <- dds$cell
```

```{r}
ggplot(gpca.dat, aes(x = dim1, y = dim2, color = dex, shape = cell)) +
  geom_point(size =3) + coord_fixed() + ggtitle("glmpca - Generalized PCA")
```

## 4.6 - MDS Plot

Another plot, very similar to the PCA plot, can be made using the multidimensional scaling (MDS) function in base R.

This type of plot is helpful when we dont have a matrix of data and only a matrix of distances.

the figure below is an example of comuting the MDS for the distances from the VST data

```{r}
mds <- as.data.frame(colData(vsd))  %>%
  cbind(cmdscale(sampleDistMatrix))
ggplot(mds, aes(x = `1`, y = `2`, color = dex, shape = cell)) +
  geom_point(size = 3) + coord_fixed() + ggtitle("MDS with VST data")
```
**MDS plot using VST data**


Next we will show the same plot but using the PoissonDistance from the heatmap calcualtions done earlier

```{r}
mdsPois <- as.data.frame(colData(dds)) %>%
  cbind(cmdscale(samplePoisDistMatrix))
ggplot(mdsPois, aes(x = `1`, y = `2`, color = dex, shape = cell)) +
  geom_point(size = 3) + coord_fixed() + ggtitle("MDS with PoissonDistances")
```
**MDS plot using the Poisson Distance.**


# 5 Differential expression analysis

## 5.1 Running the differential expression pipeline

As we have already specified an experimental design when we created the DESeqDataSet, we can run the differential expression pipeline on the raw counts with a single call to the function DESeq:

```{r}
dds <- DESeq(dds)
```

This function performs a varity of tasks, however in short what it is doing is, estimation of size factors (controlling for differences in the sequencing depth of the samples), the estimation of dispersion values for each gene, and fitting a generalized linear model.

A DESeqDataSet is returned that contains all the fitted parameters within it, and the following section describes how to extract out results tables of interest from this object.

## 5.2 - Building the results table

Calling results without any arguments will extract the estimated log2 fold changes and p values for the last variable in the design formula. If there are more than 2 levels for this variable, results will extract the results table for a comparison of the last level over the first level. The comparison is printed at the top of the output: dex trt vs untrt

```{r}
res <- results(dds)
res
```

We could have equivalently produced this results table with the following more specific command. Because dex is the last variable in the design, we could optionally leave off the contrast argument to extract the comparison of the two levels of dex.

```{r}
res <- results(dds, contrast=c("dex","trt","untrt"))

mcols(res, use.names = TRUE)
```

The first column, baseMean, is a just the average of the normalized count values, divided by the size factors, taken over all samples in the DESeqDataSet. The remaining four columns refer to a specific contrast, namely the comparison of the trt level over the untrt level for the factor variable dex. We will find out below how to obtain other contrasts.

The column log2FoldChange is the effect size estimate. It tells us how much the gene’s expression seems to have changed due to treatment with dexamethasone in comparison to untreated samples.

this estimate has an uncertainty associated with it, which is available in the column lfcSE, the standard error estimate for the log2 fold change estimate. We can also express the uncertainty of a particular effect size estimate as the result of a statistical test. The purpose of a test for differential expression is to test whether the data provides sufficient evidence to conclude that this value is really different from zero. DESeq2 performs for each gene a hypothesis test to see whether evidence is sufficient to decide against the null hypothesis that there is zero effect of the treatment on the gene and that the observed difference between treatment and control was merely caused by experimental variability (i.e., the type of variability that you can expect between different samples in the same treatment group).

We can also summarize the results with the following line of code, which reports some additional information, that will be covered in later sections.

```{r}
summary(res)
```

Note that there are many genes with differential expression due to dexamethasone treatment at the FDR level of 10%. This makes sense, as the smooth muscle cells of the airway are known to react to glucocorticoid steroids. However, there are two ways to be more strict about which set of genes are considered significant:

  - lower the false discovery rate threshold (the threshold on padj in the results table)
  - raise the log2 fold change threshold from 0 using the lfcThreshold argument of results
  
If we lower the false discovery rate threshold, we should also inform the results() function about it, so that the function can use this threshold for the optimal independent filtering that it performs:

```{r}
res.05 <- results(dds, alpha = 0.05)
table(res.05$padj < 0.05)
```

If we want to raise the log2 fold change threshold, so that we test for genes that show more substantial changes due to treatment, we simply supply a value on the log2 scale

```{r}
resLFC1 <- results(dds, lfcThreshold=1)
table(resLFC1$padj < 0.1)
```

Sometimes a subset of the p values in res will be NA (“not available”). This is DESeq’s way of reporting that all counts for this gene were zero, and hence no test was applied. In addition, p values can be assigned NA if the gene was excluded from analysis because it contained an extreme count outlier. For more information, see the outlier detection section of the DESeq2 vignette.

## 5.3 - Other comparisons

In general, the results for a comparison of any two levels of a variable can be extracted using the contrast argument to results. The user should specify three values: the name of the variable, the name of the level for the numerator, and the name of the level for the denominator. Here we extract results for the log2 of the fold change of one cell line over another:

```{r}
results(dds, contrast = c("cell", "N061011", "N61311"))
```

There are additional ways to build results tables for certain comparisons after running DESeq once. If results for an interaction term are desired, the name argument of results should be used.

## 5.4 Multiple testing 

In high-throughput biology, we are careful to not use the p values directly as evidence against the null, but to correct for multiple testing. What would happen if we were to simply threshold the p values at a low value, say 0.05? There are 5170 genes with a p value below 0.05 among the 31604 genes for which the test succeeded in reporting a p value:

```{r}
sum(res$pvalue < 0.05, na.rm=TRUE)

sum(!is.na(res$pvalue))
```


Now, assume for a moment that the null hypothesis is true for all genes, i.e., no gene is affected by the treatment with dexamethasone. Then, by the definition of the p value, we expect up to 5% of the genes to have a p value below 0.05. This amounts to 1580 genes. If we just considered the list of genes with a p value below 0.05 as differentially expressed, this list should therefore be expected to contain up to 1580 / 5170 = 31% false positives.

DESeq2 uses the Benjamini-Hochberg (BH) adjustment (Benjamini and Hochberg 1995) as implemented in the base R p.adjust function; in brief, this method calculates for each gene an adjusted p value that answers the following question: if one called significant all genes with an adjusted p value less than or equal to this gene’s adjusted p value threshold, what would be the fraction of false positives (the false discovery rate, FDR) among them, in the sense of the calculation outlined above? These values, called the BH-adjusted p values, are given in the column padj of the res object.

The FDR is a useful statistic for many high-throughput experiments, as we are often interested in reporting or focusing on a set of interesting genes, and we would like to put an upper bound on the percent of false positives in this set.

Hence, if we consider a fraction of 10% false positives acceptable, we can consider all genes with an adjusted p value below 10% = 0.1 as significant. How many such genes are there?

```{r}
sum(res$padj < 0.1, na.rm=TRUE)
```

We subset the results table to these genes and then sort it by the log2 fold change estimate to get the significant genes with the strongest down-regulation:

```{r}
resSig <- subset(res, padj < 0.1)
head(resSig[ order(resSig$log2FoldChange), ])
```

...and with the strongest up-regulation
```{r}
head(resSig[ order(resSig$log2FoldChange, decreasing = TRUE), ])
```

## 6: Plotting results

## 6.1 - Counts plot

A quick way to visualize the counts for a particular gene is to use the plotCounts function that takes as arguments the DESeqDataSet, a gene name, and the group over which to plot the counts (figure below).

```{r}
topGene <- rownames(res)[which.min(res$padj)]
plotCounts(dds, gene = topGene, intgroup=c("dex"))
```
**Normalized counts for a single gene over treatment group.**

We can also make custom plots using the ggplot function from the ggplot2 package (figures below).

```{r}
library("ggbeeswarm")
geneCounts <- plotCounts(dds, gene = topGene, intgroup = c("dex","cell"),
                         returnData = TRUE)
ggplot(geneCounts, aes(x = dex, y = count, color = cell)) +
  scale_y_log10() +  geom_beeswarm(cex = 3)

ggplot(geneCounts, aes(x = dex, y = count, color = cell, group = cell)) +
  scale_y_log10() + geom_point(size = 3) + geom_line()
```

## 6.2 - MA-plot

An MA-plot (Dudoit et al. 2002) provides a useful overview for the distribution of the estimated coefficients in the model, e.g. the comparisons of interest, across all genes. On the y-axis, the “M” stands for “minus” – subtraction of log values is equivalent to the log of the ratio – and on the x-axis, the “A” stands for “average”. You may hear this plot also referred to as a mean-difference plot, or a Bland-Altman plot.

Before making the MA-plot, we use the lfcShrink function to shrink the log2 fold changes for the comparison of dex treated vs untreated samples.

Here we specify the apeglm method for shrinking coefficients, which is good for shrinking the noisy LFC estimates while giving low bias LFC estimates for true large differences (Zhu, Ibrahim, and Love 2018). To use apeglm we specify a coefficient from the model to shrink, either by name or number as the coefficient appears in resultsNames(dds)

```{r}
library("apeglm")
resultsNames(dds)

res <- lfcShrink(dds, coef="dex_trt_vs_untrt", type="apeglm")
plotMA(res, ylim = c(-5, 5))
```

If it is necessary to specify a contrast not represented in resultsNames(dds), either of the other two shrinkage methods can be used, or in some cases, re-factoring the relevant variables and running nbinomWaldTest followed by lfcShrink is sufficient. See the DESeq2 vignette for more details.

An MA-plot of changes induced by treatment. The log2 fold change for a particular comparison is plotted on the y-axis and the average of the counts normalized by size factor is shown on the x-axis. Each gene is represented with a dot. Genes with an adjusted p value below a threshold (here 0.1, the default) are shown in red.

The DESeq2 package uses a Bayesian procedure to moderate (or “shrink”) log2 fold changes from genes with very low counts and highly variable counts, as can be seen by the narrowing of the vertical spread of points on the left side of the MA-plot. As shown above, the lfcShrink function performs this operation. For a detailed explanation of the rationale of moderated fold changes, please see the DESeq2 paper (Love, Huber, and Anders 2014).

If we had not used statistical moderation to shrink the noisy log2 fold changes, we would have instead seen the following plot:

```{r}
res.noshr <- results(dds, name="dex_trt_vs_untrt")
plotMA(res.noshr, ylim = c(-5, 5))
```

We can label individual points on the MA-plot as well. Here we use the with R function to plot a circle and text for a selected row of the results object. Within the with function, only the baseMean and log2FoldChange values for the selected rows of res are used.

```{r}
plotMA(res, ylim = c(-5,5))
topGene <- rownames(res)[which.min(res$padj)]
with(res[topGene, ], {
  points(baseMean, log2FoldChange, col="dodgerblue", cex=2, lwd=2)
  text(baseMean, log2FoldChange, topGene, pos=2, col="dodgerblue")
})
```

Another useful diagnostic plot is the histogram of the p values (figure below). This plot is best formed by excluding genes with very small counts, which otherwise generate spikes in the histogram.

```{r}
hist(res$pvalue[res$baseMean > 1], breaks = 0:20/20,
     col = "grey50", border = "white")
```

## 6.3 - Gene clustering

In the sample distance heatmap made previously, the dendrogram at the side shows us a hierarchical clustering of the samples. Such a clustering can also be performed for the genes. Since the clustering is only relevant for genes that actually carry a signal, one usually would only cluster a subset of the most highly variable genes. Here, for demonstration, let us select the 20 genes with the highest variance across samples. We will work with the VST data.


```{r}
library("genefilter")
topVarGenes <- head(order(rowVars(assay(vsd)), decreasing = TRUE), 20)
```

The heatmap becomes more interesting if we do not look at absolute expression strength but rather at the amount by which each gene deviates in a specific sample from the gene’s average across all samples. Hence, we center each genes’ values across samples, and plot a heatmap (figure below). We provide a data.frame that instructs the pheatmap function how to label the columns.

```{r}
mat  <- assay(vsd)[ topVarGenes, ]
mat  <- mat - rowMeans(mat)
anno <- as.data.frame(colData(vsd)[, c("cell","dex")])
pheatmap(mat, annotation_col = anno)
```
**Heatmap of relative VST-transformed values across samples.**


Treatment status and cell line information are shown with colored bars at the top of the heatmap. Blocks of genes that covary across patients. Note that a set of genes in the heatmap are separating the N061011 cell line from the others, and there is another set of genes for which the dexamethasone treated samples have higher gene expression.


## 6.4 Independent filtering

The MA plot highlights an important property of RNA-seq data. For weakly expressed genes, we have no chance of seeing differential expression, because the low read counts suffer from such high Poisson noise that any biological effect is drowned in the uncertainties from the sampling at a low rate. We can also show this by examining the ratio of small p values (say, less than 0.05) for genes binned by mean normalized count. We will use the results table subjected to the threshold to show what this looks like in a case when there are few tests with small p value.

In the following code chunk, we create bins using the quantile function, bin the genes by base mean using cut, rename the levels of the bins using the middle point, calculate the ratio of p values less than 0.05 for each bin, and finally plot these ratios (figure below).

```{r}
qs <- c(0, quantile(resLFC1$baseMean[resLFC1$baseMean > 0], 0:6/6))
bins <- cut(resLFC1$baseMean, qs)
levels(bins) <- paste0("~", round(signif((qs[-1] + qs[-length(qs)])/2, 2)))
fractionSig <- tapply(resLFC1$pvalue, bins, function(p)
                          mean(p < .05, na.rm = TRUE))
barplot(fractionSig, xlab = "mean normalized count",
                     ylab = "fraction of small p values")
```
**The ratio of small p values for genes binned by mean normalized count** 

The p values are from a test of log2 fold change greater than 1 or less than -1. This plot demonstrates that genes with very low mean count have little or no power, and are best excluded from testing.

At first sight, there may seem to be little benefit in filtering out these genes. After all, the test found them to be non-significant anyway. However, these genes have an influence on the multiple testing adjustment, whose performance improves if such genes are removed. By removing the low count genes from the input to the FDR procedure, we can find more genes to be significant among those that we keep, and so improved the power of our test. This approach is known as independent filtering.

The DESeq2 software automatically performs independent filtering that maximizes the number of genes with adjusted p value less than a critical value (by default, alpha is set to 0.1). This automatic independent filtering is performed by, and can be controlled by, the results function.

The term independent highlights an important caveat. Such filtering is permissible only if the statistic that we filter on (here the mean of normalized counts across all samples) is independent of the actual test statistic (the p value) under the null hypothesis. Otherwise, the filtering would invalidate the test and consequently the assumptions of the BH procedure. The independent filtering software used inside DESeq2 comes from the genefilter package, that contains a reference to a paper describing the statistical foundation for independent filtering (Bourgon, Gentleman, and Huber 2010).

## 6.5 - Independent Hypothesis Weighting

A generalization of the idea of p value filtering is to weight hypotheses to optimize power. A Bioconductor package, IHW is available that implements the method of Independent Hypothesis Weighting (Ignatiadis et al. 2016). See the DESeq2 package vignette for an example of using IHW in combination with DESeq2. In particular, the following (here, un-evaluated) code chunk can be used to perform IHW in lieu of independent filtering described above.

```{r}

library("IHW")
res.ihw <- results(dds, filterFun=ihw)

```

# 7: Annotating and exporting results

Our result table so far only contains the Ensembl gene IDs, but alternative gene names may be more informative for interpretation. Bioconductor’s annotation packages help with mapping various ID schemes to each other. We load the AnnotationDbi package and the annotation package org.Hs.eg.db:

```{r}

library("AnnotationDbi")
library("org.Hs.eg.db")

```

This is the organism annotation package (“org”) for Homo sapiens (“Hs”), organized as an AnnotationDbi database package (“db”), using Entrez Gene IDs (“eg”) as primary key. To get a list of all available key types, use:

```{r}
columns(org.Hs.eg.db)
```

We can use the mapIds function to add individual columns to our results table. We provide the row names of our results table as a key, and specify that keytype=ENSEMBL. The column argument tells the mapIds function which information we want, and the multiVals argument tells the function what to do if there are multiple possible values for a single input value. Here we ask to just give us back the first one that occurs in the database. To add the gene symbol and Entrez ID, we call mapIds twice.

```{r}
ens.str <- substr(rownames(res), 1, 15)
res$symbol <- mapIds(org.Hs.eg.db,
                     keys=ens.str,
                     column="SYMBOL",
                     keytype="ENSEMBL",
                     multiVals="first")
res$entrez <- mapIds(org.Hs.eg.db,
                     keys=ens.str,
                     column="ENTREZID",
                     keytype="ENSEMBL",
                     multiVals="first")
```

Now the results have the desired external gene IDs:

```{r}
resOrdered <- res[order(res$pvalue),]
head(resOrdered)
```

## 7.1 - Exporting results

You can easily save the results table in a CSV file that you can then share or load with a spreadsheet program such as Excel. The call to as.data.frame is necessary to convert the DataFrame object (IRanges package) to a data.frame object that can be processed by write.csv. Here, we take just the top 100 genes for demonstration.

```{r, eval=FALSE}
resOrderedDF <- as.data.frame(resOrdered)[1:100, ]
write.csv(resOrderedDF, file = "results.csv")
```

A more sophisticated way for exporting results the Bioconductor package ReportingTools (Huntley et al. 2013). ReportingTools will automatically generate dynamic HTML documents, including links to external databases using gene identifiers and boxplots summarizing the normalized counts across groups. See the ReportingTools vignettes for full details. The simplest version of creating a dynamic ReportingTools report is performed with the following code:

```{r, eval=FALSE}
library("ReportingTools")
htmlRep <- HTMLReport(shortName="report", title="My report",
                      reportDirectory="./report")
publish(resOrderedDF, htmlRep)
url <- finish(htmlRep)
browseURL(url)
```

## 7.2 - Plotting fold changes in genomic space

If we have used the tximeta function to read in the quantification data, then our DESeqDataSet object is built on top of ready-to-use Bioconductor objects specifying the genomic coordinates of the genes. We can therefore easily plot our differential expression results in genomic space. While the results or lfcShrink functions by default return a DataFrame, using the format argument, we can ask for GRanges or GRangesList output (the latter is only possible if we use the addExons function from the tximeta package upstream of creating a DESeqDataSet).

```{r}
resGR <- lfcShrink(dds, coef="dex_trt_vs_untrt", type="apeglm", format="GRanges")
resGR
```

We need to add the symbol again for labeling the genes on the plot:

```{r}
ens.str <- substr(names(resGR), 1, 15)
resGR$symbol <- mapIds(org.Hs.eg.db, ens.str, "SYMBOL", "ENSEMBL")
```

We will use the Gviz package for plotting the GRanges and associated metadata: the log fold changes due to dexamethasone treatment.

```{r}
library("Gviz")
```


The following code chunk specifies a window of 1 million base pairs upstream and downstream from the gene with the smallest p value. We create a subset of our full results, for genes within the window. We add the gene symbol as a name if the symbol exists and is not duplicated in our subset.

```{r}
window <- resGR[topGene] + 1e6
strand(window) <- "*"
resGRsub <- resGR[resGR %over% window]
naOrDup <- is.na(resGRsub$symbol) | duplicated(resGRsub$symbol)
resGRsub$group <- ifelse(naOrDup, names(resGRsub), resGRsub$symbol)
```


We create a vector specifying if the genes in this subset had a low value of padj.

```{r}
status <- factor(ifelse(resGRsub$padj < 0.05 & !is.na(resGRsub$padj),
                        "sig", "notsig"))
```

We can then plot the results using Gviz functions (figure below). We create an axis track specifying our location in the genome, a track that will show the genes and their names, colored by significance, and a data track that will draw vertical bars showing the moderated log fold change produced by DESeq2, which we know are only large when the effect is well supported by the information in the counts.

```{r}
options(ucscChromosomeNames = FALSE)
g <- GenomeAxisTrack()
a <- AnnotationTrack(resGRsub, name = "gene ranges", feature = status)
d <- DataTrack(resGRsub, data = "log2FoldChange", baseline = 0,
               type = "h", name = "log2 fold change", strand = "+")
plotTracks(list(g, d, a), groupAnnotation = "group",
           notsig = "grey", sig = "hotpink")
```
**log2 fold changes in genomic region surrounding the gene with smallest adjusted p value.**

Genes highlighted in pink have adjusted p value less than 0.1.

# 8: Removing hidden batch effects

Suppose we did not know that there were different cell lines involved in the experiment, only that there was treatment with dexamethasone. The cell line effect on the counts then would represent some hidden and unwanted variation that might be affecting many or all of the genes in the dataset. We can use statistical methods designed for RNA-seq from the sva package (Leek 2014) or the RUVSeq package (Risso et al. 2014) in Bioconductor to detect such groupings of the samples, and then we can add these to the DESeqDataSet design, in order to account for them.

The SVA package uses the term surrogate variables for the estimated variables that we want to account for in our analysis, while the RUV package uses the terms factors of unwanted variation with the acronym “Remove Unwanted Variation” explaining the package title. We first use SVA to find hidden batch effects and then RUV following.

## 8.1 SVA with DESeq2
```{r}
library("sva")
```

Below we obtain a matrix of normalized counts for which the average count across samples is larger than 1. As we described above, we are trying to recover any hidden batch effects, supposing that we do not know the cell line information. So we use a full model matrix with the dex variable, and a reduced, or null, model matrix with only an intercept term. Finally we specify that we want to estimate 2 surrogate variables. For more information read the manual page for the svaseq function by typing ?svaseq.

```{r}
dat  <- counts(dds, normalized = TRUE)
idx  <- rowMeans(dat) > 1
dat  <- dat[idx, ]
mod  <- model.matrix(~ dex, colData(dds))
mod0 <- model.matrix(~   1, colData(dds))
svseq <- svaseq(dat, mod, mod0, n.sv = 2)

## Number of significant surrogate variables is:  2 
## Iteration (out of 5 ):1  2  3  4  5

svseq$sv

```

Because we actually do know the cell lines, we can see how well the SVA method did at recovering these variables (figure below).

```{r}
par(mfrow = c(2, 1), mar = c(3,5,3,1))
for (i in 1:2) {
  stripchart(svseq$sv[, i] ~ dds$cell, vertical = TRUE, main = paste0("SV", i))
  abline(h = 0)
 }
```


**Surrogate variables 1 and 2 plotted over cell line** Here, we know the hidden source of variation (cell line), and therefore can see how the SVA procedure is able to identify a source of variation which is correlated with cell line.

Finally, in order to use SVA to remove any effect on the counts from our surrogate variables, we simply add these two surrogate variables as columns to the DESeqDataSet and then add them to the design:

```{r}
ddssva <- dds
ddssva$SV1 <- svseq$sv[,1]
ddssva$SV2 <- svseq$sv[,2]
design(ddssva) <- ~ SV1 + SV2 + dex
```

We could then produce results controlling for surrogate variables by running DESeq with the new design.

## 8.2 - Using RUV with DESeq2

We can also use the RUV method in the RUVSeq package to detect the hidden batch effects.

```{r}
library("RUVSeq")
```

We can use the RUVg function to estimate factors of unwanted variation, analogous to SVA’s surrogate variables. A difference compared to the SVA procedure above, is that we first would run DESeq and results to obtain the p-values for the analysis without knowing about the batches, e.g. just ~ dex. Supposing that we have this results table res, we then pull out a set of empirical control genes by looking at the genes that do not have a small p-value.

```{r}
set <- newSeqExpressionSet(counts(dds))
idx  <- rowSums(counts(set) > 5) >= 2
set  <- set[idx, ]
set <- betweenLaneNormalization(set, which="upper")
not.sig <- rownames(res)[which(res$pvalue > .1)]
empirical <- rownames(set)[ rownames(set) %in% not.sig ]
set <- RUVg(set, empirical, k=2)
pData(set)
```

We can plot the factors estimated by RUV:

```{r}
par(mfrow = c(2, 1), mar = c(3,5,3,1))
for (i in 1:2) {
  stripchart(pData(set)[, i] ~ dds$cell, vertical = TRUE, main = paste0("W", i))
  abline(h = 0)
 }
```
**Factors of unwanted variation plotted over cell line.**

As before, if we wanted to control for these factors, we simply add them to the DESeqDataSet and to the design:

```{r}
ddsruv <- dds
ddsruv$W1 <- set$W_1
ddsruv$W2 <- set$W_2
design(ddsruv) <- ~ W1 + W2 + dex
```

We would then run DESeq with the new design to re-estimate the parameters and results.

# 9: Time Course Experiements

DESeq2 can be used to analyze time course experiments, for example to find those genes that react in a condition-specific manner over time, compared to a set of baseline samples. Here we demonstrate a basic time course analysis with the fission data package, which contains gene counts for an RNA-seq time course of fission yeast (Leong et al. 2014). The yeast were exposed to oxidative stress, and half of the samples contained a deletion of the gene atf21. We use a design formula that models the strain difference at time 0, the difference over time, and any strain-specific differences over time (the interaction term strain:minute).

```{r}
library("fission")
data("fission")
ddsTC <- DESeqDataSet(fission, ~ strain + minute + strain:minute)
```

The following chunk of code performs a likelihood ratio test, where we remove the strain-specific differences over time. Genes with small p values from this test are those which at one or more time points after time 0 showed a strain-specific effect. Note therefore that this will not give small p values to genes that moved up or down over time in the same way in both strains.

```{r}
ddsTC <- DESeq(ddsTC, test="LRT", reduced = ~ strain + minute)
resTC <- results(ddsTC)
resTC$symbol <- mcols(ddsTC)$symbol
head(resTC[order(resTC$padj),], 4)
```

This is just one of the tests that can be applied to time series data. Another option would be to model the counts as a smooth function of time, and to include an interaction term of the condition with the smooth function. It is possible to build such a model using spline basis functions within R, and another, more modern approach is using Gaussian processes (Tonner et al. 2017).

We can plot the counts for the groups over time using ggplot2, for the gene with the smallest adjusted p value, testing for condition-dependent time profile and accounting for differences at time 0 (figure below). Keep in mind that the interaction terms are the difference between the two groups at a given time after accounting for the difference at time 0.

```{r}
fiss <- plotCounts(ddsTC, which.min(resTC$padj), 
                   intgroup = c("minute","strain"), returnData = TRUE)
fiss$minute <- as.numeric(as.character(fiss$minute))
ggplot(fiss,
  aes(x = minute, y = count, color = strain, group = strain)) + 
  geom_point() + stat_summary(fun.y=mean, geom="line") +
  scale_y_log10()
```
**Normalized counts for a gene with condition-specific changes over time.**

Wald tests for the log2 fold changes at individual time points can be investigated using the test argument to results:

```{r}
resultsNames(ddsTC)
res30 <- results(ddsTC, name="strainmut.minute30", test="Wald")
res30[which.min(resTC$padj),]
```

We can furthermore cluster significant genes by their profiles. We extract a matrix of the shrunken log2 fold changes using the coef function:

```{r}
betas <- coef(ddsTC)
colnames(betas)
```

We can now plot the log2 fold changes in a heatmap (figure below).

```{r}
topGenes <- head(order(resTC$padj),20)
mat <- betas[topGenes, -c(1,2)]
thr <- 3 
mat[mat < -thr] <- -thr
mat[mat > thr] <- thr
pheatmap(mat, breaks=seq(from=-thr, to=thr, length=101),
         cluster_col=FALSE)
```

**Heatmap of log2 fold changes for genes with smallest adjusted p value** The bottom set of genes show strong induction of expression for the baseline samples in minutes 15-60 (red boxes in the bottom left corner), but then have slight differences for the mutant strain (shown in the boxes in the bottom right corner).

# 10: Session Information

As the last part of this document, we call the function sessionInfo, which reports the version numbers of R and all the packages used in this session. It is good practice to always keep such a record of this as it will help to track down what has happened in case an R script ceases to work or gives different results because the functions have been changed in a newer version of one of your packages. By including it at the bottom of a script, your reports will become more reproducible.

The session information should also always be included in any emails to the Bioconductor support site along with all code used in the analysis.

```{r}
sessionInfo()
```

